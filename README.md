# Video Understanding (视频理解) ![](https://visitor-badge.glitch.me/badge?page_id=putao537.Awesome-Video-Understanding)

<h4 align="center">Everything about video understanding.</h4>

<p align="center">
  <strong><a href="#0">Papers</a></strong> •
  <strong><a href="#1">Tutorials</a></strong> •
  <strong><a href="#2">Talks</a></strong> •
  <strong><a href="#3">Blogs</a></strong> •
</p>

<div align=center>
  <img src='./Figures/WeChat.png' width="50%" />
</div>

<div align=center>
  <a href="https://www.zhihu.com/people/putao537"><img src="https://img.shields.io/badge/知乎-blue" alt=""></a> <a href="https://wx.zsxq.com/dweb2/index/group/15288888851422"><a href="https://space.bilibili.com/11722513"><img src="https://img.shields.io/badge/Bilibili-blue" alt=""></a>
</div>

<h2 id="0">0. Papers</h2>

<details>
  <summary> Video Action Recognition </summary>
  
### 2022
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| CVPR | Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Bridge-Prompt_Towards_Ordinal_Action_Understanding_in_Instructional_Videos_CVPR_2022_paper.pdf)/[Code](https://github.com/ttlmh/Bridge-Prompt) |
| CVPR | Temporal Alignment Networks for Long-term Video | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Han_Temporal_Alignment_Networks_for_Long-Term_Video_CVPR_2022_paper.pdf)/[Code](https://www.robots.ox.ac.uk/~vgg/research/tan/) |
  
</details>
  
<details>
  <summary> Video Retrieval </summary>
  
### 2022
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| CVPR | Everything at Once – Multi-modal Fusion Transformer for Video Retrieval | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Shvetsova_Everything_at_Once_-_Multi-Modal_Fusion_Transformer_for_Video_Retrieval_CVPR_2022_paper.pdf)/[Code](https://github.com/ninatu/everything_at_once) | 
 
  
</details>
  
<details>
  <summary> Video Captioning </summary>

### 2022
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| CVPR | End-to-End Generative Pretraining for Multimodal Video Captioning | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Seo_End-to-End_Generative_Pretraining_for_Multimodal_Video_Captioning_CVPR_2022_paper.pdf) |
  
</details>
  
<details>
  <summary> Video Scene Graph Generation </summary>
 
### 2022
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| CVPR | Classification-Then-Grounding: Reformulating Video Scene Graphs as Temporal Bipartite Graphs | [PDF](https://arxiv.org/pdf/2112.04222.pdf)/[Code](https://github.com/Dawn-LX/VidSGG-BIG) |
| CVPR | Dynamic Scene Graph Generation via Anticipatory Pre-training | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Dynamic_Scene_Graph_Generation_via_Anticipatory_Pre-Training_CVPR_2022_paper.pdf) |
| CVPR | VRDFormer: End-to-End Video Visual Relation Detection with Transformers | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Zheng_VRDFormer_End-to-End_Video_Visual_Relation_Detection_With_Transformers_CVPR_2022_paper.pdf)/[Code](https://github.com/zhengsipeng/VRDFormer_VRD) |
  
### 2021
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| TNNLS | What and When to Look?: Temporal Span Proposal Network for Video Visual Relation Detection | [PDF](https://arxiv.org/pdf/2107.07154.pdf) |
| ICCV | Spatial-Temporal Transformer for Dynamic Scene Graph Generation | [PDF](https://arxiv.org/pdf/2107.12309.pdf)/[Code](https://github.com/yrcong/STTran) |
| ICCV | Target Adaptive Context Aggregation for Video Scene Graph Generation | [PDF](https://arxiv.org/pdf/2108.08121.pdf)/[Code](https://github.com/MCG-NJU/TRACE) |
| ACM MM | Video Relation Detection via Tracklet based Visual Transformer | [PDF](https://dl.acm.org/doi/pdf/10.1145/3474085.3479231)/[Code](https://github.com/Dawn-LX/VidVRD-tracklets) |

### 2020
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |  
| CVPR | Action Genome: Actions as Composition of Spatio-temporal Scene Graphs | [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Ji_Action_Genome_Actions_As_Compositions_of_Spatio-Temporal_Scene_Graphs_CVPR_2020_paper.pdf)/[Dataset (Action Genome)](https://www.actiongenome.org/) |
| CVPR | Beyond Short-Term Snippet: Video Relation Detection with Spatio-Temporal Global Context | [PDF](https://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Beyond_Short-Term_Snippet_Video_Relation_Detection_With_Spatio-Temporal_Global_Context_CVPR_2020_paper.pdf) 
| ECCV | Visual Relation Grounding in Videos | [PDF](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123510443.pdf)/[Code](https://github.com/doc-doc/vRGV) |  
### 2019~2017
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| CVPR'19 | Video Relationship Reasoning using Gated Spatio-Temporal Energy Graph | [PDF](https://openaccess.thecvf.com/content_CVPR_2019/papers/Tsai_Video_Relationship_Reasoning_Using_Gated_Spatio-Temporal_Energy_Graph_CVPR_2019_paper.pdf) |
| ACM MM'19 | Video Relation Detection with Spatio-Temporal Graph | [PDF](https://dl.acm.org/doi/pdf/10.1145/3343031.3351058) |
| ICMR'19 | Annotating Objects and Relations in User-Generated Videos | [PDF](https://dl.acm.org/doi/pdf/10.1145/3323873.3325056)/[Dataset (VidOR)](https://xdshang.github.io/docs/vidor.html) |
| ACM MM'17 | Video Visual Relation Detection | [PDF](https://dl.acm.org/doi/pdf/10.1145/3123266.3123380)/[Dataset (VidVRD)](https://xdshang.github.io/docs/imagenet-vidvrd.html) |
  
</details>
  
<details>
  <summary> Video Question Answering </summary>
  
### 2022
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| CVPR | Invariant Grounding for Video Question Answering | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Li_Invariant_Grounding_for_Video_Question_Answering_CVPR_2022_paper.pdf)/[Code](https://github.com/yl3800/IGV) |
  
</details>
  
<details>
  <summary> Unsupervised Video Understanding </summary>

### 2022
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
| CVPR | Motion-aware Contrastive Video Representation Learning via Foreground-background Merging | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Ding_Motion-Aware_Contrastive_Video_Representation_Learning_via_Foreground-Background_Merging_CVPR_2022_paper.pdf)/[Code](https://github.com/Mark12Ding/FAME) |
| CVPR | Long-Short Temporal Contrastive Learning of Video Transformers | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Wang_Long-Short_Temporal_Contrastive_Learning_of_Video_Transformers_CVPR_2022_paper.pdf) |
| CVPR | TransRank: Self-supervised Video Representation Learning via Ranking-based Transformation Recognition | [PDF](https://openaccess.thecvf.com/content/CVPR2022/papers/Duan_TransRank_Self-Supervised_Video_Representation_Learning_via_Ranking-Based_Transformation_Recognition_CVPR_2022_paper.pdf)/[Code](https://github.com/kennymckormick/TransRank) |
  
</details>
  
<h2 id="1">1. Tutorials</h2>

<details> <summary> Tutorials published on 2021  </summary>
  
|  **Pub.**  | **Title**                                                    |                          **Links**                           |
| :--------: | :----------------------------------------------------------- | :----------------------------------------------------------: |
|  |  |  |

</details>  
  
  
<h2 id="2">2. Talks</h2>
  
  
<h2 id="3">3. Blogs</h2>

